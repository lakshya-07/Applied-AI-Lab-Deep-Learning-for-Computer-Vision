{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<p>\n",
    "  <b>AI Lab: Deep Learning for Computer Vision</b><br>\n",
    "  <b><a href=\"https://www.wqu.edu/\">WorldQuant University</a></b>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "  <p>\n",
    "    <center><b>Usage Guidelines</b></center>\n",
    "  </p>\n",
    "  <p>\n",
    "    This file is licensed under <a href=\"https://creativecommons.org/licenses/by-nc-nd/4.0/\">Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International</a>.\n",
    "  </p>\n",
    "  <p>\n",
    "    You <b>can</b>:\n",
    "    <ul>\n",
    "      <li><span style=\"color: green\">✓</span> Download this file</li>\n",
    "      <li><span style=\"color: green\">✓</span> Post this file in public repositories</li>\n",
    "    </ul>\n",
    "    You <b>must always</b>:\n",
    "    <ul>\n",
    "      <li><span style=\"color: green\">✓</span> Give credit to <a href=\"https://www.wqu.edu/\">WorldQuant University</a> for the creation of this file</li>\n",
    "      <li><span style=\"color: green\">✓</span> Provide a <a href=\"https://creativecommons.org/licenses/by-nc-nd/4.0/\">link to the license</a></li>\n",
    "    </ul>\n",
    "    You <b>cannot</b>:\n",
    "    <ul>\n",
    "      <li><span style=\"color: red\">✗</span> Create derivatives or adaptations of this file</li>\n",
    "      <li><span style=\"color: red\">✗</span> Use this file for commercial purposes</li>\n",
    "    </ul>\n",
    "  </p>\n",
    "  <p>\n",
    "    Failure to follow these guidelines is a violation of your terms of service and could lead to your expulsion from WorldQuant University and the revocation your certificate.\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by importing the packages we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import torch\n",
    "import torchvision\n",
    "from facenet_pytorch import MTCNN\n",
    "from PIL import Image\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also print out the version numbers for our libraries, including Python. This way anyone who reviews our work knows exactly what software we used in case they want to reproduce our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Platform:\", sys.platform)\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"---\")\n",
    "print(\"torch version : \", torch.__version__)\n",
    "print(\"torchvision version : \", torchvision.__version__)\n",
    "print(\"PIL version : \", PIL.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also make use of GPUs, so the device should be `cuda`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\"Using {device} device.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing a MTCNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll perform face detection using a MTCNN network from `facenet_pytorch` library. This model is able to simultaneously propose bounding boxes of faces, determine detection probabilities, and detect facial landmarks like eyes, nose and mouth.\n",
    "\n",
    "Let's start by initializing the model. Here are a couple of arguments we get to set:\n",
    "- `device`: The device on which to run the model. \n",
    "- `keep_all`: A boolean determining if all detected faces are returned or not.\n",
    "- `min_face_size`: Minimum face size (in pixels) to search for in the image.\n",
    "- `post_process`: A boolean determining if we want image standardization of detected faces. This is advised before proceeding with face recognition models, but if we want face images that are returned to us to look normal to the human eye, we can set `post_process=False`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Task 4.3.1:** Initialize a MTCNN model. Make sure to use a GPU, keep all detected faces and set minimum face size to search for to be 60."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTCNN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcnn = MTCNN(device=..., keep_all=..., min_face_size=..., post_process=False)\n",
    "\n",
    "print(mtcnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get an image that we'll work with. In the previous lesson, we extracted some frames from the video interview with Mary Kom. Those images are in directory `project4`. In there we created a subdirectory `data` within which we have the `extracted_frames` subdirectory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4.3.2:** Create a variable for the current working directory using `pathlib` syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_work_dir = ...\n",
    "\n",
    "print(curr_work_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4.3.3:** Create an absolute path for the `extracted_frames` directory using the `pathlib` syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_frames_dir = ...\n",
    "\n",
    "print(extracted_frames_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4.3.4:** Create a file path to the sample image we'll be working with. The image is in the `extracted_frames` directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image_filename = \"frame_320.jpg\"\n",
    "sample_image_path = ...\n",
    "\n",
    "sample_image = Image.open(sample_image_path)\n",
    "sample_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well done! We now have a sample image with several human faces. Let's detect them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bounding Boxes of Detected Faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to detect faces and obtain their bounding boxes, we need to use the `detect` method on the MTCNN model and pass in the sample image. This returns both the bounding boxes of detected faces as well as the predicted probability that the object in a given bounding box is indeed a face."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4.3.5:** Use the `detect` method on the MTCNN model we initialized in one of the previous tasks. Make sure to pass in the `sample_image`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes, probs = ...\n",
    "\n",
    "print(\"boxes type:\", type(boxes))\n",
    "print(\"probs type:\", type(probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We now have two arrays. Array `boxes` contains the bounding boxes of the detected faces and `probs` contains the probabilities.\n",
    "\n",
    "Let's look at the `boxes` array first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(boxes)\n",
    "print(boxes.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4.3.6:** Using `boxes`, compute how many faces were detected in the sample image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_detected_faces = ...\n",
    "\n",
    "print(number_of_detected_faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we again look at the image we're working with, we can indeed see three faces. We're on the right path!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's investigate the probabilities that the model returned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4.3.7:** Using `probs`, determine for how many of the faces detected did the model predict with at least 99% probability that it's a face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_faces = ...\n",
    "\n",
    "print(num_faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the model is very certain that all of the detected faces are indeed faces!\n",
    "\n",
    "Now let's plot the bounding boxes together with the sample image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4.3.8:** Fill in the missing code below to iterate over all of the bounding boxes and plot them on top of the sample image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(sample_image)\n",
    "\n",
    "for ... in ...:\n",
    "    rect = plt.Rectangle(\n",
    "        (box[0], box[1]), box[2] - box[0], box[3] - box[1], fill=False, color=\"blue\"\n",
    "    )\n",
    "    ax.add_patch(rect)\n",
    "plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Facial Landmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MTCNN not only detects faces but can also mark facial landmarks such as eyes, nose, and mouth in each detected face. \n",
    "\n",
    "The way to obtain the facial landmarks together with bounding boxes and probabilities is to again use the `detect` method on the MTCNN model. But this time together with the sample image, we need to pass in `landmarks=True`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4.3.9:** Use the `detect` method on the MTCNN model such that we'll get bounding boxes, probabilities and facial landmarks returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes, probs, landmarks = ...\n",
    "\n",
    "print(\"boxes type:\", type(boxes))\n",
    "print(\"probs type:\", type(probs))\n",
    "print(\"landmarks type:\", type(landmarks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The facial landmarks detected by the model on each face are:\n",
    "- left eye,\n",
    "- right eye,\n",
    "- nose,\n",
    "- left mouth corner,\n",
    "- right mouth corner.\n",
    "\n",
    "Let's make sure that the shape of the landmarks array matches what we'd expect given that six faces were detected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4.3.10:** Print the shape of the landmarks array returned by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We have 3 faces detected and on each face, we have 5 facial landmarks and 2 coordinates locating each landmark. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4.3.11:** Fill in the missing code to plot the bounding boxes as well as the facial landmarks on top of the sample image. We recommend using `zip` on `boxes` and `landmarks` in the `for` loop that you need to fill in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(sample_image)\n",
    "\n",
    "for box, landmark in ...:\n",
    "    rect = plt.Rectangle(\n",
    "        (box[0], box[1]), box[2] - box[0], box[3] - box[1], fill=False, color=\"blue\"\n",
    "    )\n",
    "    ax.add_patch(rect)\n",
    "    for point in landmark:\n",
    "        ax.plot(point[0], point[1], marker=\"o\", color=\"red\")\n",
    "plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cropping out Detected Faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to proceed with further face analysis like for example perform face recognition, it's a good idea to crop out the detected faces. That way further analysis can focus only on the relevant parts of the image. \n",
    "\n",
    "So let's learn how we can crop out the detected faces!\n",
    "\n",
    "In order to get the PyTorch tensors of the detected faces instead of the bounding boxes, we need to call the MTCNN object directly and just pass in the image we're working with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4.3.12:** Use the MTCNN model that we initialized in the first task and pass it the `sample_image`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = ...\n",
    "\n",
    "print(faces.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like this returned three small images, each with 3 color channels and 160 width and 160 height. Let's plot these 3 images!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4.3.13:** Create a grid of these three images by using `make_grid` from `torchvision.utils` and passing in `faces`. Use `nrow=3` so we'll have all 3 images in one row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Grid = ...\n",
    "\n",
    "print(Grid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot the grid of images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Grid.permute(1, 2, 0).int())\n",
    "plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtained the cropped faces that were detected. Hooray!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare a Subset of Images for Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conclude this lesson, we'll prepare a subset of images for the next lesson where we'll work on face embeddings or faceprints. These are numerical representations of a face that are needed for tasks like face recognition or verification.\n",
    "\n",
    "Let's create a directory of selected images that we'll work with in the next lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4.3.14:** Make a directory into which we'll put the selected images. Make sure you do it such that no error is raised even if the directory already exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = curr_work_dir / \"project4\" / \"data\" / \"images\"\n",
    "images_dir.mkdir(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4.3.15:** Make a subdirectory in the `images` directory and call it `mary_kom`. Again make sure you do it such that no error is raised even if the directory already exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mary_kom_dir = ...\n",
    "\n",
    "# Now Create `mary_kom` directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good job! The directory you just created will be the directory into which we'll put the selected images. \n",
    "\n",
    "Let's make a list of frames that we want to use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mary_kom_imgs = [\n",
    "    \"frame_80.jpg\",\n",
    "    \"frame_115.jpg\",\n",
    "    \"frame_120.jpg\",\n",
    "    \"frame_125.jpg\",\n",
    "    \"frame_135.jpg\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4.3.16:** Iterate over `mary_kom_imgs` list of image filenames and create a list of absolute paths to each image using `pathlib` syntax. Remember that the images are in the `extracted_frames` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mary_kom_img_paths = ...\n",
    "\n",
    "print(\"Number of images we'll use:\", len(mary_kom_img_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we copy these images over to `mary_kom` directory, let's just look at them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 5, figsize=(10, 8))\n",
    "\n",
    "for i, ax in enumerate(axs):\n",
    "    ax.imshow(Image.open(mary_kom_img_paths[i]))\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4.3.17:** Iterate over `mary_kom_img_paths` in order to copy these selected images into `mary_kom` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_path in ...:\n",
    "    shutil.copy(image_path, mary_kom_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of files in mary_kom directory:\", len(list(mary_kom_dir.iterdir())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also get some images of the interviewer, so we'll have more than one face we can potentially identify. We'll call that directory `ranveer`, since that's the interviewer's first name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4.3.18:** Make a subdirectory in the `images` directory and call it `ranveer`. Again make sure you do it such that no error is raised even if the directory already exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranveer_dir = ...\n",
    "\n",
    "# Now Create `ranveer` directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make another list, this time of images of the interviewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranveer_imgs = [\n",
    "    \"frame_10.jpg\",\n",
    "    \"frame_40.jpg\",\n",
    "    \"frame_270.jpg\",\n",
    "    \"frame_365.jpg\",\n",
    "    \"frame_425.jpg\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4.3.19:** Iterate over `ranveer_imgs` list of image filenames and create a list of absolute paths to each image using `pathlib` syntax. Remember that the images are in the `extracted_frames` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranveer_img_paths = ...\n",
    "\n",
    "print(\"Number of images we'll use:\", len(ranveer_img_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at these as well before we copy them to the new directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 5, figsize=(10, 8))\n",
    "\n",
    "for i, ax in enumerate(axs):\n",
    "    ax.imshow(Image.open(ranveer_img_paths[i]))\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They're all images of just the interviewer, so we're ready to copy them over."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4.3.20:** Iterate over `ranveer_img_paths` in order to copy these selected images into `ranveer` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_path in ...:\n",
    "    shutil.copy(image_path, ranveer_dir)\n",
    "\n",
    "print(\"Number of files in ranveer directory:\", len(list(ranveer_dir.iterdir())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now we have a set of images ready for the next lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "This file &#169; 2024 by [WorldQuant University](https://www.wqu.edu/) is licensed under [CC BY-NC-ND 4.0](https://creativecommons.org/licenses/by-nc-nd/4.0/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
