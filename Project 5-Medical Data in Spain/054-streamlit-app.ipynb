{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "  <b>AI Lab: Deep Learning for Computer Vision</b><br>\n",
    "  <b><a href=\"https://www.wqu.edu/\">WorldQuant University</a></b>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "  <p>\n",
    "    <center><b>Usage Guidelines</b></center>\n",
    "  </p>\n",
    "  <p>\n",
    "    This file is licensed under <a href=\"https://creativecommons.org/licenses/by-nc-nd/4.0/\">Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International</a>.\n",
    "  </p>\n",
    "  <p>\n",
    "    You <b>can</b>:\n",
    "    <ul>\n",
    "      <li><span style=\"color: green\">✓</span> Download this file</li>\n",
    "      <li><span style=\"color: green\">✓</span> Post this file in public repositories</li>\n",
    "    </ul>\n",
    "    You <b>must always</b>:\n",
    "    <ul>\n",
    "      <li><span style=\"color: green\">✓</span> Give credit to <a href=\"https://www.wqu.edu/\">WorldQuant University</a> for the creation of this file</li>\n",
    "      <li><span style=\"color: green\">✓</span> Provide a <a href=\"https://creativecommons.org/licenses/by-nc-nd/4.0/\">link to the license</a></li>\n",
    "    </ul>\n",
    "    You <b>cannot</b>:\n",
    "    <ul>\n",
    "      <li><span style=\"color: red\">✗</span> Create derivatives or adaptations of this file</li>\n",
    "      <li><span style=\"color: red\">✗</span> Use this file for commercial purposes</li>\n",
    "    </ul>\n",
    "  </p>\n",
    "  <p>\n",
    "    Failure to follow these guidelines is a violation of your terms of service and could lead to your expulsion from WorldQuant University and the revocation your certificate.\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be developing some of the individual parts of the web app in this Jupyter Notebook before transferring them to a separate `.py` file. Let's start by importing what we'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torchvision\n",
    "from medigan import Generators\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll define the GAN models that a user will be able to select from. We'll use the `medigan` library which contains many pre-trained generative adversarial networks that can create synthetic medical images. You can read more about medigan [here](https://github.com/RichardObi/medigan), including a list of available models [here](https://github.com/RichardObi/medigan?tab=readme-ov-file#available-models). Note that some models are very large and may cause the server to crash."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5.4.1:** Add another `medigan` model to the `model_ids` list.\n",
    "\n",
    "> We recommend using \"00019_PGGAN_CHEST_XRAY\" to help ensure you successfully complete this task and achieve results that closely match your instructor's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ids = [\n",
    "    \"00001_DCGAN_MMG_CALC_ROI\",\n",
    "    \"00002_DCGAN_MMG_MASS_ROI\",\n",
    "    \"00003_CYCLEGAN_MMG_DENSITY_FULL\",\n",
    "    \"00004_PIX2PIX_MMG_MASSES_W_MASKS\",\n",
    "    ... # New model\n",
    "]\n",
    "\n",
    "# Check number of models\n",
    "assert len(model_ids) == 5, \"Add another model\"\n",
    "\n",
    "# Check that each item in model_ids is valid\n",
    "for m_id in model_ids:\n",
    "    assert m_id in Generators().list_models()\n",
    "else:\n",
    "    print(f\"All {len(model_ids)} models are valid!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving Code to a Python File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Streamlit framework expects all the code to be in a Python file, not a Jupyter Notebook. We'll need to move our code to a `.py` file. The `app.py` file has sections for all the elements we'll need. Right now, move the following elements over to `app.py`:\n",
    "\n",
    "- All the imports, except `import streamlit as st` which is already provided.\n",
    "- The `model_ids` list as is.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5.4.2:** Fill in the `app.py` file with imports and `model_ids` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import app\n",
    "\n",
    "print(\"Models available in app:\")\n",
    "for model_id in app.model_ids:\n",
    "    print(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the core of a Streamlit app is the `main` function, which defines the structure and behavior of the web app. Let's add a title, a model selection dropdown menu, and a selector for the number of images. We'll use Streamlit functions for each of these elements. For example, `st.sidebar.number_input` displays a numeric input widget, which you can learn more about [here](https://docs.streamlit.io/develop/api-reference/widgets/st.number_input). We'll use this widget to allow the user to dynamically select the num_images. The minimum number of images should be 1, and the maximum number of images could be 7. This range provides flexibility while ensuring the generation process doesn't take too long."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5.4.3:** Add values for the keyword arguments `min_value=` and `max_value=` in the `st.sidebar.number_input` function call in the `main` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Main Block in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of `app.py`, you'll find:\n",
    "\n",
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "    ...\n",
    "```\n",
    "\n",
    "This code snippet, often called the 'main block' or 'main guard' in Python, checks whether the script is being run directly, rather than being imported as a module. The main block is a common part of Python scripts. It provides a clear entry point for the program, allowing the script to be both importable and executable. When the script is run directly, the code inside the block will execute. If it's imported as a module, this block is skipped, enabling reusable code without triggering the main program logic.\n",
    "\n",
    "In our `app.py`, the main block should call the `main()` function, which presents the home elements for the app. While Streamlit runs the entire script from top to bottom, using this structure is still considered good practice. It keeps your code organized and ready for future expansion or reuse in other projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5.4.4:** Add a call to the `main` function in the main block."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running The App"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the core of the app is written, it's time to run it. To start the app, run `streamlit run app.py` at the command line. Since this app is running on a server, the additional argument `--browser.serverAddress 0.0.0.0` and `--server.port 9000` is required. Open a new terminal, navigate to the directory containing `app.py`, and run this command:\n",
    "\n",
    "```bash\n",
    "$ streamlit run app.py --browser.serverAddress 0.0.0.0 --server.port 9000\n",
    "```\n",
    "\n",
    "The app is now running. Although Streamlit is designed for local machines, we're running it on a server. You can ignore the default message for running it locally: \n",
    "\n",
    "```text\n",
    "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
    "```\n",
    "\n",
    "```bash\n",
    "  You can now view your Streamlit app in your browser.\n",
    "\n",
    "  URL: http://0.0.0.0:9000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5.4.5:** Start the app at the terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access the Streamlit app, switch to the next tab that is named `Streamlit App` as shown in the following picture:\n",
    "\n",
    "![](streamlit_tab.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5.4.6:** Navigate to the URL for the app."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the web app, you can select the GAN model and the number of images from the dropdown menus. The app displays a 'Generate Images' button, but there is no associated functionality. If you press the 'Generate Images' button, the app will display an error message. \n",
    "\n",
    "So let's shut the app off and implement the image generation functionality. To stop the app, press Ctrl + C in the terminal where the app process is running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5.4.7:** Stop the app in the terminal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the skeleton of the app is working, we can start working on the PyTorch elements. The `torch_images` function is responsible for loading and transforming images using PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_images(num_images, model_id):\n",
    "    generators = Generators()\n",
    "    dataloader = generators.get_as_torch_dataloader(\n",
    "        model_id=model_id,\n",
    "        install_dependencies=True,\n",
    "        num_samples=num_images,\n",
    "        prefetch_factor=None,\n",
    "    )\n",
    "\n",
    "    images = []\n",
    "    for batch_idx, data_dict in enumerate(dataloader):\n",
    "        image_list = []\n",
    "        for i in data_dict:\n",
    "            if \"sample\" in i:\n",
    "                sample = data_dict.get(\"sample\")\n",
    "                if sample.dim() == 4:\n",
    "                    sample = sample.squeeze(0).permute(2, 0, 1)\n",
    "\n",
    "                sample = to_pil_image(sample).convert(\"RGB\")\n",
    "                # Convert the image to a PyTorch tensor\n",
    "                transform = torchvision.transforms.Compose(\n",
    "                    [\n",
    "                        torchvision.transforms.ToTensor(),\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                # Apply the transform to your PIL image\n",
    "                sample = transform(sample)\n",
    "                image_list.append(sample)\n",
    "\n",
    "            # Preprocess the mask\n",
    "            if \"mask\" in i:\n",
    "                mask = data_dict.get(\"mask\")\n",
    "                if mask.dim() == 4:\n",
    "                    mask = mask.squeeze(0).permute(2, 0, 1)\n",
    "                mask = to_pil_image(mask).convert(\"RGB\")\n",
    "                mask = transform(mask)\n",
    "                image_list.append(mask)\n",
    "\n",
    "        # Organize the grid to have 'sample' images per row\n",
    "        Grid = make_grid(image_list, nrow=2)\n",
    "\n",
    "        # Change Grid tensor to be a consistent shape\n",
    "        # The Grid tensor has shape [1, 128, 128, 1] in some models\n",
    "        if Grid.dim() == 4:\n",
    "            # Remove the singleton batch dimension\n",
    "            Grid = Grid.squeeze(0)\n",
    "            if Grid.size(-1) == 1:\n",
    "                # Remove the singleton channel dimension (assuming grayscale)\n",
    "                Grid = Grid.squeeze(-1)\n",
    "            else:\n",
    "                raise ValueError(\"Expected a single channel (grayscale) image.\")\n",
    "\n",
    "        # Convert the tensor grid to a PIL Image for display\n",
    "        img = torchvision.transforms.ToPILImage()(Grid)\n",
    "        images.append(img)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5.4.8:** Call the `torch_images` function to generate a single image. The existing code will display it on the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = ...\n",
    "image[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for the app to use the `torch_images` function, the function needs to be moved into `app.py`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5.4.9:** Copy the `torch_images` function from this notebook to `app.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify that the app is able to generate images, delete the notebook version of `torch_images`, then import and run the `torch_images` function from `app.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del torch_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5.4.10:** Import `torch_images` from `app.py` to call the function and display a single image on the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the function from the app\n",
    "\n",
    "# Call the function\n",
    "image = torch_images(num_images=1, model_id=model_ids[4])\n",
    "# Display the image on the screen\n",
    "image[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the Images in the App"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's integrate the PyTorch code with the Streamlit framework. In `app.py`, the `generate_images` function calls the `torch_images` function and uses Streamlit to display the resulting images in the web app."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5.4.11:** Add the parameters to the `torch_images` function call in the `generate_images` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can add functionality to the \"Generate Images\" button in the app. The `st.sidebar.button` function displays a button widget, which you can learn more about [here](https://docs.streamlit.io/develop/api-reference/widgets/st.button). We'll use this widget to let the user generate images. Once the button is pressed, the app will call the `generate_images` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5.4.12:** Add the parameters to the `generate_images` function call in the `st.sidebar.button` function call in the `main` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Completed App"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's restart the Streamlit apps by opening a terminal, navigating to the directory containing `app.py`, and run this command:\n",
    "\n",
    "```bash\n",
    "$ streamlit run app.py --browser.serverAddress 0.0.0.0 --server.port 9000\n",
    "```\n",
    "\n",
    "Switch to the tab \"Streamlit App\" again to preview your app.\n",
    "\n",
    "All features of the app are now fully functional. After selecting the desired model and specifying the number of images to generate, you can click the 'Generate Images' button. While the model is generating images, you will see a 'RUNNING' message in the upper-right corner of the browser.\n",
    "\n",
    "To stop the app, press Ctrl + C in the terminal where the app process is running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5.4.13:** Start your app, go to your app page, and play around with it! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great work on building a web app! You’ve successfully created a functional tool that allows users to generate images using GAN models, providing them with the flexibility to choose different models and control the number of images produced. Along the way, you learned how to use Streamlit for web development and enhanced your general Python coding skills. This project demonstrates how powerful machine learning models can be integrated into a user-friendly application. 🙌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "This file &#169; 2024 by [WorldQuant University](https://www.wqu.edu/) is licensed under [CC BY-NC-ND 4.0](https://creativecommons.org/licenses/by-nc-nd/4.0/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
