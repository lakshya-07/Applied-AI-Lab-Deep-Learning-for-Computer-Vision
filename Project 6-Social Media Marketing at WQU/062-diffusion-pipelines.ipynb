{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stable Diffusion Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by importing the same libraries as before, and also defining the device and correct type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import diffusers\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import transformers\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "from torchinfo import summary\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "    dtype = torch.float16\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    dtype = torch.float32\n",
    "\n",
    "print(f\"Using {device} device with {dtype} data type.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the same prompt as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"A red bird flies through a blue sky over a green tree.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this seems like a lot of work to run Stable Diffusion, you're not alone.  That's why the `StableDiffusionPipeline` was created.  It incorporates all of these steps into a single pipeline object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = diffusers.StableDiffusionPipeline.from_pretrained(\n",
    "    \"CompVis/stable-diffusion-v1-4\", torch_dtype=dtype\n",
    ")\n",
    "pipeline.to(device)\n",
    "\n",
    "print(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can call it with a prompt, and it returns a container with a list of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pipeline(prompt)\n",
    "\n",
    "print(res)\n",
    "print(len(res.images))\n",
    "# Display the first (and only, in this case) image\n",
    "display(res.images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to taking a single prompt as input, the pipeline accepts a list of prompts and generates an image for each.  By passing the same prompt in multiple times, we can use this to generate several candidate images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6.2.20:** Generate four images for our prompt using the pipeline.  We've provided code that will display all of them.\n",
    "\n",
    "To reduce the VRAM consumption and avoid \"Out of Memory\" problems, we'll reduce the size of the desired images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list containing the prompt four times and pass it to the pipeline.\n",
    "images = ...\n",
    "\n",
    "for im in images:\n",
    "    display(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pipeline` takes a `guidance_scale` argument.  Small values let the model be more creative, and larger values make it hew more closely to the prompt.  The default value is 7.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6.2.21:** Generate images at small guidance scale (2) and large guidance scale (25) values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_guidance = pipeline(...).images[0]\n",
    "large_guidance = pipeline(...).images[0]\n",
    "\n",
    "print(\"Small guidance\")\n",
    "display(small_guidance)\n",
    "print(\"Large guidance\")\n",
    "display(large_guidance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "The behavior at different guidance levels becomes more apparent as you see more examples.  You may wish to run the above cell several times.  Alternatively, you can alter it to produce several images at each guidance level.\n",
    "</div>\n",
    "\n",
    "We can also adjust the number of denoising steps, with the `num_inference_steps` parameter.  The default is 50 steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6.2.22:** Run the pipeline with only a few (10) and with many (250) steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_steps = pipeline(...).images[0]\n",
    "many_steps = pipeline(...).images[0]\n",
    "\n",
    "print(\"Few steps\")\n",
    "display(few_steps)\n",
    "print(\"Many steps\")\n",
    "display(many_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These models tend to be trained on images from sites like Flickr and DeviantArt.  The text descriptions are assembled from summaries, comments, and tags assigned to the images.  That last component means that the training descriptions often consist of a series of keywords, rather than a coherent paragraph about the image.\n",
    "\n",
    "Our prompts will perform best when they resemble the training data.  Many people have had success by creating prompts that contain lists of keywords and tags that reflect the style they desire.  Here are a couple of different sets of style keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "styles = [\n",
    "    # A cartoon in Studio Ghibli style\n",
    "    \"cartoon, animated, Studio Ghibli style, cute, Japanese animation\",\n",
    "    # A photograph on film suggests an artistic approach\n",
    "    \"photograph, film, 35 mm camera\",\n",
    "    # A computer rendering.  The \"arguments\" at the end don't directly\n",
    "    # affect the image, but they make the model adjust the image to\n",
    "    # look like images tagged with these arguments.\n",
    "    \"rendered in unreal engine, hyper-realistic, volumetric lighting, --ar 9:16 --hd --q 2\",\n",
    "    # A watercolor painting\n",
    "    \"painting, watercolors, pastel, composition\",\n",
    "    # Add your own, too!\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can steer the model towards our style by adding these to our prompt.  For example, to generate our bird in a cartoon style, we could do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "styled_prompt = f\"{prompt} {styles[0]}\"\n",
    "image = pipeline(styled_prompt).images[0]\n",
    "\n",
    "print(styled_prompt)\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6.2.23:** Generate an image using our prompt and each of these styles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "styled_prompts = ...\n",
    "images = ...\n",
    "\n",
    "for p, i in zip(styled_prompts, images):\n",
    "    print(p)\n",
    "    display(i)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
