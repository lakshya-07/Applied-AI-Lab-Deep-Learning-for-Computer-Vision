# Applied-AI-Lab-Deep-Learning-for-Computer-Vision
***WorldQuant University***

## Project 1: Wildlife Conservation in CÃ´te d'Ivoire
### Project Description: Animal Classification in Wildlife Preserve

**Objective**: This project centers around a data science competition aimed at helping scientists track animals in a wildlife preserve. The goal is to classify images captured by camera traps to identify which animal, if any, is present. The competition will enhance your machine learning skills by developing powerful neural network models capable of processing and classifying images into multiple categories.

**Key Components**:

1. **Image Processing**:
   - Learn how to read and prepare image files for machine learning tasks.

2. **Neural Network Models**:
   - Use PyTorch to manipulate tensors and build neural network models.
   - Construct a Convolutional Neural Network (CNN) tailored for image classification tasks.

3. **Model Predictions**:
   - Apply the trained model to make predictions on new images.
   - Classify images into various categories based on the presence of different animals.

4. **Competition Submission**:
   - Learn how to turn model predictions into a submission for the competition, ensuring your solutions meet the competition's requirements.

**Skills and Knowledge Gained**:

- Reading and preparing image files for machine learning.
- Using PyTorch to manipulate tensors and build neural network models.
- Building a Convolutional Neural Network for image classification.
- Making predictions with the trained model on new images.
- Preparing and submitting your model's predictions for a competition.

Join this project to advance your machine learning expertise and contribute to wildlife conservation efforts by accurately classifying animals in a wildlife preserve!
### Data & Models: https://drive.google.com/drive/folders/1F33eaw1xqzMkM6rURw2UxiLig8lYhziW?usp=sharing 
  
## Project 2: Crop Disease in Uganda
### Project Description: Crop Disease Classification in Uganda

**Objective**: This project involves working with a dataset of crop disease images from Uganda. You will build and train a convolutional neural network (CNN) to classify these images into five distinct categories. The project aims to enhance your understanding of computer vision models and their performance optimization using advanced techniques.

**Key Components**:

1. **Dataset Exploration**:
   - Explore and analyze the crop image dataset to understand its structure and characteristics.

2. **Model Building and Training**:
   - Build and train a CNN to classify images into five categories of crop diseases.
   - Utilize Transfer Learning by adapting a pre-trained image classification model to improve performance.

3. **Performance Improvement**:
   - Identify and address model overfitting using appropriate techniques.
   - Employ k-fold cross-validation to evaluate model performance and ensure its robustness.

4. **Optimization Techniques**:
   - Utilize Callbacks like Learning Rate Scheduling, Checkpointing, and Early Stopping to optimize the training process and enhance model accuracy and efficiency.

**Skills and Knowledge Gained**:

- Exploring and understanding a crop image dataset.
- Building and training a convolutional neural network for image classification.
- Improving model performance using Transfer Learning.
- Identifying and mitigating model overfitting.
- Evaluating model performance with k-fold cross-validation.
- Using Callbacks to optimize model training.

Embark on this project to develop your skills in computer vision and create a robust crop disease classification system!
### Data & Models: https://drive.google.com/drive/folders/1CU71T2_IM8aAjLv2N_v1j9br5s3roY88?usp=sharing

## Project 3: Traffic Monitoring in Bangladesh
### Project Description: Real-Time Traffic Object Detection in Dhaka

**Objective**: The project focuses on analyzing traffic video feed data from Dhaka, Bangladesh. The goal is to detect and label objects such as cars and people in real-time using advanced object detection models. You'll start with a pre-trained model and extend it to detect custom objects specific to your traffic analysis task.

**Key Components**:

1. **Data Handling**: 
   - Work with XML data containing bounding box information.
   - Extract individual frames from video files for further analysis.

2. **Object Detection Models**:
   - Utilize the pre-trained YOLO (You Only Look Once) object detection model for initial object detection tasks.
   - Extend the YOLO model to recognize custom objects, adapting it for traffic feed data analysis.

3. **Data Augmentation**:
   - Enhance the model's ability to generalize by augmenting the data during training, improving detection accuracy and robustness.

**Skills and Knowledge Gained**:

- Handling XML data with bounding box information.
- Extracting frames from video files for object detection.
- Applying the pre-trained YOLO object detection model.
- Training the YOLO model to extend its capabilities for custom object detection.
- Using data augmentation techniques to improve model performance.

Dive into this project to leverage cutting-edge models and develop a robust system for real-time traffic analysis!
### Data: https://drive.google.com/file/d/1Ly6ESIGHiO5WUBfkQ8BBRUTg9SG3MuWS/view?usp=sharing

## Project 4: Celebrity Sightings in India
### Project Description: Face Detection and Recognition with Mary Kom

**Objective**: The project aims to teach you how to perform face detection and recognition tasks by using a video of an interview with Indian Olympic boxer Mary Kom. You will utilize advanced pre-trained models to recognize faces and create a practical application.

**Key Components**:

1. **Pre-trained Models**: 
   - **MTCNN (Multi-task Cascaded Convolutional Network)**: Used for detecting face bounding boxes and cropping faces from images.
   - **Inception-ResNet**: Used to create face embeddings for face recognition tasks.

2. **Face Embeddings**:
   - Extract face embeddings for Mary Kom and her interviewer using selected video frames.
   - Create a library of known face embeddings to facilitate face recognition.

3. **Recognition Tasks**:
   - Detect faces in new images by comparing them with the library of known faces.
   - Determine if an image contains a face that matches the known face embeddings.

4. **Application Development**:
   - Build a Flask app to allow users to upload images and perform face recognition tasks through a user-friendly interface.

**Skills and Knowledge Gained**:

- Using pre-trained MTCNN and Inception-ResNet V1 models from facenet_pytorch.
- Obtaining face bounding boxes and cropped faces using MTCNN.
- Creating face embeddings using Inception-ResNet.
- Constructing a library of known face embeddings.
- Determining if an image contains a face from the library of known faces.
- Building a Flask application for face recognition tasks.

Embark on this project to harness the power of state-of-the-art models and create a seamless face recognition application!
### Data: https://drive.google.com/file/d/1dulBV6uu3iC3eeSYeE6A4qCpUJi9S9B7/view?usp=sharing

## Project 5: Medical Data in Spain

### Project Description: Generating Medical Images with GANs

**Objective**: The tasks involved in this project were successfully completed to demonstrate the generation of medical images, such as X-rays and MRIs, using Generative Adversarial Networks (GANs). Both custom-built GANs and pre-trained models were utilized for this purpose. Additionally, a Streamlit web application was developed to enable users to interact with the GAN, and Git and GitHub were used to manage and track the project's code.

**Key Components**:

1. **Generative Adversarial Networks (GANs)**:
   - A custom GAN was designed and trained to generate realistic medical images.
   - A pre-trained GAN was employed to enhance efficiency in the creation of synthetic datasets.

2. **Synthetic Data Utilization**:
   - Realistic medical images, including X-rays and MRIs, were generated using the GAN.
   - These synthetic images were utilized to train and evaluate machine learning models.

3. **Web App Development**:
   - An interactive web application was created using Streamlit, providing users with the ability to generate and visualize medical images.

4. **Version Control and Collaboration**:
   - Code changes were tracked using Git, and the project was shared through GitHub repositories to ensure collaborative development and proper version control.

**Skills and Knowledge Gained**:

- The process of designing and training GANs for image generation was mastered.
- Pre-trained GANs were effectively utilized for creating synthetic datasets.
- A web application was built using Streamlit to provide user interaction.
- Proficiency in Git and GitHub was acquired for version control and collaboration.
- The applications of GANs in medical imaging and synthetic data generation were explored comprehensively.

Through this project, the potential of GANs in medical image generation was successfully demonstrated, and a practical interactive application was provided for users to experience the technology.

### Data & Models: https://drive.google.com/drive/folders/1rfj7ZpYV4rb1pOpncX6RfclRsDBrL9Pa?usp=sharing

## Project 6: Social Media Marketing at WQU 

### Project Description: Real-Time Meme Creation Using Text-to-Image Generation  

**Objective**: This project focuses on leveraging Stable Diffusion for generating custom images based on text descriptions. Participants will assemble the Stable Diffusion pipeline using pre-trained neural networks and fine-tune these models to incorporate unique image data. The goal is to design a system that can produce creative, meme-worthy images and deploy a user-friendly Streamlit application to allow non-technical teams to interact effortlessly with the model.

**Key Components**:

1. **Stable Diffusion Pipeline**:  
   Construct the image generation pipeline by integrating pre-trained neural network components. Learn how Stable Diffusion processes text-to-image tasks and adapts to custom requirements.

2. **Fine-Tuning Models**:  
   Enhance the model's performance with Low-Rank Adaptation (LoRA) techniques, enabling it to generate images aligned to custom specifications.

3. **Streamlit Application Development**:  
   Create a front-end application using Streamlit to enable real-time interaction with the fine-tuned Stable Diffusion model. Simplify the process for non-technical users.

4. **Deployment**:  
   Deploy the application to Streamlit Community Cloud, ensuring accessibility for external users and making the system widely usable.

**Skills and Knowledge Gained**:

- Understanding the individual components of the Stable Diffusion pipeline.
- Fine-tuning Stable Diffusion models with LoRA for custom image generation.
- Developing interactive apps using Streamlit for seamless model use.
- Deploying apps to the cloud for broader accessibility and usability.

### Data & Models: 

### Credits
These project are completed by me as part of the ***WorldQuant University*** Applied AI Lab program.

### License
This project is licensed- see the ***[LICENSE](https://creativecommons.org/licenses/by-nc-nd/4.0/)*** file for details.
